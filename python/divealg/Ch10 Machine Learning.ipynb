{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10: Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44387, 534)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rk/qwqd81bx00b1rl2fj8gy_vnc0000gn/T/ipykernel_27186/3778618770.py:2: DtypeWarning: Columns (164) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ess = pd.read_csv('ess.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ess = pd.read_csv('ess.csv')\n",
    "print(ess.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5\n",
      "1    5\n",
      "2    8\n",
      "3    8\n",
      "4    5\n",
      "Name: happy, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(ess.loc[:,'happy'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess = ess.loc[ess['sclmeet'] <= 10,:].copy()\n",
    "ess = ess.loc[ess['rlgdgr'] <= 10,:].copy()\n",
    "ess = ess.loc[ess['hhmmb'] <= 50,:].copy()\n",
    "ess = ess.loc[ess['netusoft'] <= 5,:].copy()\n",
    "ess = ess.loc[ess['agea'] <= 200,:].copy()\n",
    "ess = ess.loc[ess['health'] <= 5,:].copy()\n",
    "ess = ess.loc[ess['happy'] <= 10,:].copy()\n",
    "ess = ess.loc[ess['eduyrs'] <= 100,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            name  essround  edition    proddate  idno cntry  nwspol  netusoft  \\\n",
      "0      ESS8e02_1         8      2.1  01.12.2018     1    AT     120         4   \n",
      "1      ESS8e02_1         8      2.1  01.12.2018     2    AT     120         5   \n",
      "2      ESS8e02_1         8      2.1  01.12.2018     4    AT      30         2   \n",
      "3      ESS8e02_1         8      2.1  01.12.2018     6    AT      30         5   \n",
      "4      ESS8e02_1         8      2.1  01.12.2018    10    AT      30         5   \n",
      "...          ...       ...      ...         ...   ...   ...     ...       ...   \n",
      "44382  ESS8e02_1         8      2.1  01.12.2018  1303    SI      90         2   \n",
      "44383  ESS8e02_1         8      2.1  01.12.2018  1304    SI      40         5   \n",
      "44384  ESS8e02_1         8      2.1  01.12.2018  1305    SI     240         5   \n",
      "44385  ESS8e02_1         8      2.1  01.12.2018  1306    SI       0         5   \n",
      "44386  ESS8e02_1         8      2.1  01.12.2018  1307    SI      60         5   \n",
      "\n",
      "       netustm  ppltrst  ...  inwsmm  inwdde  inwmme  inwyye  inwehh  inwemm  \\\n",
      "0          180        8  ...      37       5      12    2016       8      33   \n",
      "1          120        6  ...      39      25      11    2016      11      10   \n",
      "2         6666        5  ...      17      22      11    2016      18       0   \n",
      "3          120        6  ...       9      11      10    2016      19      59   \n",
      "4          180        5  ...      31       1      12    2016      11      49   \n",
      "...        ...      ...  ...     ...     ...     ...     ...     ...     ...   \n",
      "44382     6666        1  ...      30      19      10    2016       8      37   \n",
      "44383      120        3  ...      38      30       9    2016       9      45   \n",
      "44384      150        3  ...       9      26       9    2016      10      17   \n",
      "44385      120        5  ...       0       2      11    2016      18      25   \n",
      "44386      120        7  ...       9      25      10    2016      17      10   \n",
      "\n",
      "       inwtm   dweight   pspwght   pweight  \n",
      "0       50.0  0.611677  1.178496  0.370393  \n",
      "1       86.0  1.223354  0.899472  0.370393  \n",
      "2       38.0  0.389058  0.315753  0.370393  \n",
      "3       46.0  0.642594  0.472467  0.370393  \n",
      "4       70.0  3.432402  2.246706  0.370393  \n",
      "...      ...       ...       ...       ...  \n",
      "44382   62.0  1.000000  0.835442  0.134491  \n",
      "44383   60.0  1.000000  0.756328  0.134491  \n",
      "44384   62.0  1.000000  0.856172  0.134491  \n",
      "44385   78.0  1.000000  0.756328  0.134491  \n",
      "44386   55.0  1.000000  0.802472  0.134491  \n",
      "\n",
      "[43329 rows x 534 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ess.loc[ess['eduyrs'] <= 100,:].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary split: happiness as a function of social activity\n",
    "import numpy as np\n",
    "social = list(ess.loc[:,'sclmeet'])\n",
    "happy = list(ess.loc[:,'happy'])\n",
    "low_social_happiness = [hap for soc,hap in zip(social,happy) if soc <= 5]\n",
    "high_social_happiness = [hap for soc,hap in zip(social,happy) if soc > 5]\n",
    "\n",
    "meanlower = np.mean(low_social_happiness)\n",
    "meanhigher = np.mean(high_social_happiness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average happiness of someone with low social activity is 7.2\n",
      "The average happiness of someone with high social activity is 7.8\n"
     ]
    }
   ],
   "source": [
    "print('The average happiness of someone with low social activity is ' + str(round(meanlower,1)))\n",
    "print('The average happiness of someone with high social activity is ' + str(round(meanhigher,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76229.87414197999\n"
     ]
    }
   ],
   "source": [
    "# Error prediction. Sum of errors approaching zero is better.\n",
    "lowererrors = [abs(lowhappy - meanlower) for lowhappy in low_social_happiness]\n",
    "highererrors = [abs(highhappy - meanhigher) for highhappy in low_social_happiness]\n",
    "\n",
    "total_error = sum(lowererrors) + sum(highererrors)\n",
    "print(total_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check every possible split point to find which leads to the lowest error.\n",
    "def get_splitpoint(allvalues,predictedvalues):\n",
    "    lowest_error = float('inf')\n",
    "    best_split = None\n",
    "    best_lowermean = np.mean(predictedvalues)\n",
    "    best_highermean = np.mean(predictedvalues)\n",
    "    for pctl in range(0,100):    # \"pctl\" = \"percentile\"\n",
    "        split_candidate = np.percentile(allvalues,pctl)    # The pctl-th percentile of the data\n",
    "        \n",
    "        loweroutcomes = [outcome for value,outcome in zip(allvalues,predictedvalues) if value <= split_candidate]    # Create a list of the happiness levels of people whose sclmeet <= the split candidate\n",
    "        higheroutcomes = [outcome for value, outcome in zip(allvalues,predictedvalues) if value > split_candidate]    # Create a list of the happiness levels of people whose sclmeet > the split candidate\n",
    "        \n",
    "        if np.min([len(loweroutcomes),len(higheroutcomes)]) > 0:\n",
    "            meanlower = np.mean(loweroutcomes)\n",
    "            meanhigher = np.mean(higheroutcomes)\n",
    "            \n",
    "            lowererrors = [abs(outcome - meanlower) for outcome in loweroutcomes]    # Check the errors from using that split candidate\n",
    "            highererrors = [abs(outcome - meanhigher) for outcome in higheroutcomes]\n",
    "            \n",
    "            total_error = sum(lowererrors) + sum(highererrors)\n",
    "            \n",
    "            if total_error < lowest_error:\n",
    "                best_split = split_candidate\n",
    "                lowest_error = total_error\n",
    "                best_lowermean = meanlower\n",
    "                best_highermean = meanhigher\n",
    "    return(best_split,lowest_error,best_lowermean,best_highermean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 60860.029867951016, 6.839403436723225, 7.620055170794695)\n"
     ]
    }
   ],
   "source": [
    "# Find the best split point for happiness as a function of the number of household members\n",
    "allvalues = list(ess.loc[:,'hhmmb'])\n",
    "predictedvalues = list(ess.loc[:,'happy'])\n",
    "print(get_splitpoint(allvalues,predictedvalues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing splitting variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each available variable and check whether splitting on that variable produces the smallest error.\n",
    "\n",
    "def getsplit(data,variables,outcome_variable):\n",
    "    best_var = ''\n",
    "    lowest_error = float('inf')\n",
    "    best_split = None\n",
    "    predictedvalues = list(data.loc[:,outcome_variable])\n",
    "    best_lowermean = -1\n",
    "    best_highermean = -1\n",
    "    for var in variables:    # Iterates get_splitpoint() over a list of variables\n",
    "        allvalues = list(data.loc[:,var])\n",
    "        splitted = get_splitpoint(allvalues,predictedvalues)\n",
    "        \n",
    "        if(splitted[1] < lowest_error):\n",
    "            best_split = splitted[0]\n",
    "            lowest_error = splitted[1]\n",
    "            best_var = var\n",
    "            best_lowermean = splitted[2]\n",
    "            best_highermean = splitted[3]\n",
    "            \n",
    "    generated_tree = [[best_var,float('-inf'),best_split,best_lowermean],[best_var,best_split,float('inf'),best_highermean]]\n",
    "    \n",
    "    return(generated_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['netusoft', -inf, 4.0, 7.041597337770383], ['netusoft', 4.0, inf, 7.73042471042471]]\n"
     ]
    }
   ],
   "source": [
    "# Find the split points of happiness as a function of a series of variables\n",
    "# Recall that getsplit() optimizes for lowest error\n",
    "\n",
    "variables = ['rlgdgr','hhmmb','netusoft','agea','eduyrs']\n",
    "outcome_variable = 'happy'\n",
    "print(getsplit(ess,variables,outcome_variable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getsplit() 2.0: Generates tree to a certain depth\n",
    "\n",
    "maxdepth = 3\n",
    "def getsplit(depth,data,variables,outcome_variable):\n",
    "    best_var = ''\n",
    "    lowest_error = float('inf')\n",
    "    best_split = None\n",
    "    predictedvalues = list(data.loc[:,outcome_variable])\n",
    "    best_lowermean = -1\n",
    "    best_highermean = -1\n",
    "    for var in variables:    # Iterates get_splitpoint() over a list of variables\n",
    "        allvalues = list(data.loc[:,var])\n",
    "        splitted = get_splitpoint(allvalues,predictedvalues)\n",
    "        \n",
    "        if(splitted[1] < lowest_error):\n",
    "            best_split = splitted[0]\n",
    "            lowest_error = splitted[1]\n",
    "            best_var = var\n",
    "            best_lowermean = splitted[2]\n",
    "            best_highermean = splitted[3]\n",
    "            \n",
    "    generated_tree = [[best_var,float('-inf'),best_split,[]],[best_var,best_split,float('inf'),[]]]    # Now adds empty lists to generated_tree rather than means. Lists will contain additional branches. \n",
    "    \n",
    "    if depth < maxdepth:\n",
    "        splitdata1=data.loc[data[best_var] <= best_split,:]\n",
    "        splitdata2=data.loc[data[best_var] > best_split,:]\n",
    "        if len(splitdata1.index) > 10 and len(splitdata2.index) > 10:\n",
    "            generated_tree[0][3] = getsplit(depth + 1,splitdata1,variables,outcome_variable)\n",
    "            generated_tree[1][3] = getsplit(depth + 1,splitdata2,variables,outcome_variable)\n",
    "        else:\n",
    "            depth = maxdepth + 1\n",
    "            generated_tree[0][3] = best_lowermean\n",
    "            generated_tree[1][3] = best_highermean\n",
    "    else:\n",
    "        generated_tree[0][3] = best_lowermean\n",
    "        generated_tree[1][3] = best_highermean\n",
    "    return(generated_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['netusoft', -inf, 4.0, [['hhmmb', -inf, 4.0, [['agea', -inf, 15.0, 8.035714285714286], ['agea', 15.0, inf, 6.997666564322997]]], ['hhmmb', 4.0, inf, [['eduyrs', -inf, 11.0, 7.263969171483622], ['eduyrs', 11.0, inf, 8.0]]]]], ['netusoft', 4.0, inf, [['hhmmb', -inf, 1.0, [['agea', -inf, 66.0, 7.135361428970136], ['agea', 66.0, inf, 7.621993127147766]]], ['hhmmb', 1.0, inf, [['rlgdgr', -inf, 5.0, 7.743893678160919], ['rlgdgr', 5.0, inf, 7.9873320537428025]]]]]]\n"
     ]
    }
   ],
   "source": [
    "# Creates a decision tree with a depth of two.\n",
    "variables = ['rlgdgr','hhmmb','netusoft','agea','eduyrs']\n",
    "outcome_variable = 'happy'\n",
    "maxdepth = 2\n",
    "print(getsplit(0,ess,variables,outcome_variable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['health', -inf, 2.0, [['hhmmb', -inf, 1.0, [['health', -inf, 1.0, [['agea', -inf, 49.0, 7.782231852654387], ['agea', 49.0, inf, 7.992150706436421]]], ['health', 1.0, inf, [['agea', -inf, 66.0, 7.055858882822344], ['agea', 66.0, inf, 7.723076923076923]]]]], ['hhmmb', 1.0, inf, [['netusoft', -inf, 3.0, [['agea', -inf, 61.0, 7.4860335195530725], ['agea', 61.0, inf, 7.9896719319562575]]], ['netusoft', 3.0, inf, [['agea', -inf, 29.0, 7.944661921708185], ['agea', 29.0, inf, 7.9972535414859784]]]]]]], ['health', 2.0, inf, [['health', -inf, 3.0, [['netusoft', -inf, 1.0, [['rlgdgr', -inf, 5.0, 6.410942956926659], ['rlgdgr', 5.0, inf, 7.04384133611691]]], ['netusoft', 1.0, inf, [['agea', -inf, 78.0, 6.998687147170802], ['agea', 78.0, inf, 7.735042735042735]]]]], ['health', 3.0, inf, [['health', -inf, 4.0, [['eduyrs', -inf, 13.0, 6.002436647173489], ['eduyrs', 13.0, inf, 6.356462585034014]]], ['health', 4.0, inf, [['hhmmb', -inf, 1.0, 4.2552301255230125], ['hhmmb', 1.0, inf, 5.56824512534819]]]]]]]]\n"
     ]
    }
   ],
   "source": [
    "# Creates a decision tree with a depth of three. Note the additional variable.\n",
    "variables = ['rlgdgr','hhmmb','netusoft','agea','eduyrs','health']\n",
    "outcome_variable = 'happy'\n",
    "maxdepth = 3\n",
    "print(getsplit(0,ess,variables,outcome_variable))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.056947608200455, 6.056947608200455, 6.800675675675675, 6.9994697773064685, 7.972410568155249, 6.9994697773064685, 6.9994697773064685, 6.9994697773064685, 7.972410568155249, 6.9994697773064685, 6.9994697773064685, 6.9994697773064685, 6.00487567040468, 6.9994697773064685, 6.00487567040468, 7.972410568155249, 7.999195847649682, 6.9994697773064685, 6.9994697773064685, 6.9994697773064685]\n"
     ]
    }
   ],
   "source": [
    "# Determine someone's predicted level of happiness based on their ESS response\n",
    "\n",
    "def get_prediction(observation,tree):\n",
    "    j = 0\n",
    "    keepgoing = True\n",
    "    prediction = -1\n",
    "    while(keepgoing):\n",
    "        j = j + 1\n",
    "        variable_tocheck = tree[0][0]\n",
    "        bound1 = tree[0][1]\n",
    "        bound2 = tree[0][2]\n",
    "        bound3 = tree[1][2]\n",
    "        if observation.loc[variable_tocheck] < bound2:\n",
    "            tree = tree[0][3]\n",
    "        else:\n",
    "            tree = tree[1][3]\n",
    "        if isinstance(tree,float):\n",
    "            keepgoing = False\n",
    "            prediction = tree\n",
    "    return(prediction)\n",
    "\n",
    "predictions=[]\n",
    "outcome_variable = 'happy'\n",
    "maxdepth = 4\n",
    "thetree = getsplit(0,ess,variables,outcome_variable)\n",
    "for k in range(0,20):\n",
    "    observation = ess.loc[k,:]\n",
    "    predictions.append(get_prediction(observation,thetree))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "20",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3619'>3620</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2131\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2140\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 20",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/graftoncook/Documents/python/01 Basics/divealg/Ch10 Machine Learning.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/graftoncook/Documents/python/01%20Basics/divealg/Ch10%20Machine%20Learning.ipynb#ch0000026?line=0'>1</a>\u001b[0m predictions \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/graftoncook/Documents/python/01%20Basics/divealg/Ch10%20Machine%20Learning.ipynb#ch0000026?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(ess\u001b[39m.\u001b[39mindex)):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/graftoncook/Documents/python/01%20Basics/divealg/Ch10%20Machine%20Learning.ipynb#ch0000026?line=2'>3</a>\u001b[0m     observation \u001b[39m=\u001b[39m ess\u001b[39m.\u001b[39;49mloc[k,:]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/graftoncook/Documents/python/01%20Basics/divealg/Ch10%20Machine%20Learning.ipynb#ch0000026?line=3'>4</a>\u001b[0m     predictions\u001b[39m.\u001b[39mappend(get_prediction(observation,thetree))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/graftoncook/Documents/python/01%20Basics/divealg/Ch10%20Machine%20Learning.ipynb#ch0000026?line=4'>5</a>\u001b[0m ess\u001b[39m.\u001b[39mloc[:,\u001b[39m'\u001b[39m\u001b[39mpredicted\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m predictions\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=958'>959</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=959'>960</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m--> <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=960'>961</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=961'>962</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=962'>963</a>\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=963'>964</a>\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py:1140\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=1137'>1138</a>\u001b[0m \u001b[39mwith\u001b[39;00m suppress(IndexingError):\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=1138'>1139</a>\u001b[0m     tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_ellipsis(tup)\n\u001b[0;32m-> <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=1139'>1140</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_lowerdim(tup)\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=1141'>1142</a>\u001b[0m \u001b[39m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=1142'>1143</a>\u001b[0m tup \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_tuple_indexer(tup)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py:867\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=862'>863</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, key \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tup):\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=863'>864</a>\u001b[0m     \u001b[39mif\u001b[39;00m is_label_like(key):\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=864'>865</a>\u001b[0m         \u001b[39m# We don't need to check for tuples here because those are\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=865'>866</a>\u001b[0m         \u001b[39m#  caught by the _is_nested_tuple_indexer check above.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=866'>867</a>\u001b[0m         section \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=868'>869</a>\u001b[0m         \u001b[39m# We should never have a scalar section here, because\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=869'>870</a>\u001b[0m         \u001b[39m#  _getitem_lowerdim is only called after a check for\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=870'>871</a>\u001b[0m         \u001b[39m#  is_scalar_access, which that would be.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=871'>872</a>\u001b[0m         \u001b[39mif\u001b[39;00m section\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim:\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=872'>873</a>\u001b[0m             \u001b[39m# we're in the middle of slicing through a MultiIndex\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=873'>874</a>\u001b[0m             \u001b[39m# revise the key wrt to `section` by inserting an _NS\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py:1202\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=1199'>1200</a>\u001b[0m \u001b[39m# fall thru to straight lookup\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=1200'>1201</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m-> <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=1201'>1202</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_label(key, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py:1153\u001b[0m, in \u001b[0;36m_LocIndexer._get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=1150'>1151</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_label\u001b[39m(\u001b[39mself\u001b[39m, label, axis: \u001b[39mint\u001b[39m):\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=1151'>1152</a>\u001b[0m     \u001b[39m# GH#5667 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexing.py?line=1152'>1153</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49mxs(label, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/generic.py:3864\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/generic.py?line=3861'>3862</a>\u001b[0m             new_index \u001b[39m=\u001b[39m index[loc]\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/generic.py?line=3862'>3863</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/generic.py?line=3863'>3864</a>\u001b[0m     loc \u001b[39m=\u001b[39m index\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/generic.py?line=3865'>3866</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(loc, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/generic.py?line=3866'>3867</a>\u001b[0m         \u001b[39mif\u001b[39;00m loc\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mbool_:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3620'>3621</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3621'>3622</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3622'>3623</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3623'>3624</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3624'>3625</a>\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3625'>3626</a>\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3626'>3627</a>\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   <a href='file:///opt/homebrew/lib/python3.9/site-packages/pandas/core/indexes/base.py?line=3627'>3628</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 20"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for k in range(0,len(ess.index)):\n",
    "    observation = ess.loc[k,:]\n",
    "    predictions.append(get_prediction(observation,thetree))\n",
    "ess.loc[:,'predicted'] = predictions\n",
    "errors = abs(ess.loc[:,'predicted'] - ess.loc[:,'happy'])\n",
    "print(np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4209904647906406\n"
     ]
    }
   ],
   "source": [
    "# Define test and training data\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(512)\n",
    "ess_shuffled = ess.reindex(np.random.permutation(ess.index)).reset_index(drop = True)    # Use numpy to shuffle the data\n",
    "training_data = ess_shuffled.loc[0:37000,:]\n",
    "test_data = ess_shuffled.loc[37001:,:].reset_index(drop = True)\n",
    "\n",
    "thetree = getsplit(0,training_data,variables,outcome_variable)\n",
    "\n",
    "predictions = []\n",
    "for k in range(0,len(test_data.index)):\n",
    "    observation = test_data.loc[k,:]\n",
    "    predictions.append(get_prediction(observation,thetree))\n",
    "test_data.loc[:,'predicted'] = predictions\n",
    "errors = abs(test_data.loc[:,'predicted'] - test_data.loc[:,'happy'])\n",
    "print(np.mean(errors))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
