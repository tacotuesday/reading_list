{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"heart_disease.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [0.82 0.8  0.77 0.78 0.77]\n",
      "Mean Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Build a classifier to obtain a baseline score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "# Initialize the classifier with booster='gbtree' and objective='binary:logistic'\n",
    "model = XGBClassifier(booster=\"gbtree\", objective=\"binary:logistic\", random_state=2)\n",
    "\n",
    "# Score the baseline model using cross_val_scores and numpy\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "scores = cross_val_score(model, X, y, cv=5)\n",
    "print(\"Accuracy:\", np.round(scores, 2))\n",
    "print(\"Mean Accuracy:\", np.round(np.mean(scores), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using StratifiedKFold helps ensure that the folds are representative of the whole dataset\n",
    "# This ensures consistent results across cross_val_score, GridSearchCV, and RandomizedSearchCV.\n",
    "# Import and initialize the StratifiedKFold object\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: [0.72 0.77 0.75 0.85 0.87]\n",
      "Mean Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "# Score the baseline model with consistent folds.\n",
    "scores = cross_val_score(model, X, y, cv=kfold)\n",
    "print(\"Accuracy:\", np.round(scores, 2))\n",
    "print(\"Mean Accuracy:\", np.round(np.mean(scores), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining GridSearchCV with RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "\n",
    "# Define a grid_search function with the params dictionary as input, along with random=False\n",
    "def grid_search(params, random=False):\n",
    "    xgb = XGBClassifier(booster=\"gbtree\", objective=\"binary:logistic\", random_state=2)\n",
    "    if random:\n",
    "        grid = RandomizedSearchCV(xgb, params, cv=kfold, n_iter=20, n_jobs=-1)\n",
    "    else:\n",
    "        grid = GridSearchCV(xgb, params, cv=kfold, n_jobs=-1)\n",
    "    grid.fit(X, y)\n",
    "    best_params = grid.best_params_\n",
    "    print(\"Best params:\", best_params)\n",
    "    best_score = grid.best_score_\n",
    "    print(\"Best score:\", np.round(best_score, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 400}\n",
      "Best score: 0.796\n"
     ]
    }
   ],
   "source": [
    "# Tune n_estimators\n",
    "# One strategy for finding an ideal value for n_estimators is using early stopping.\n",
    "grid_search(params={\"n_estimators\": [100, 200, 400, 800]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.05}\n",
      "Best score: 0.802\n"
     ]
    }
   ],
   "source": [
    "# Tune learning_rate\n",
    "grid_search(params={\"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 6}\n",
      "Best score: 0.793\n"
     ]
    }
   ],
   "source": [
    "# Tune max_depth, the length of the tree. The default value is 6.\n",
    "grid_search(params={\"max_depth\": [2, 3, 5, 6, 8]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'gamma': 0}\n",
      "Best score: 0.793\n"
     ]
    }
   ],
   "source": [
    "# Tune gamma, the Lagrange multiplier.\n",
    "# gamma provides a threshold that nodes must surpass before making further splits on a branch of the tree.\n",
    "grid_search(params={\"gamma\": [0, 0.1, 0.5, 1, 2, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'min_child_weight': 3}\n",
      "Best score: 0.799\n"
     ]
    }
   ],
   "source": [
    "# Tune min_child_weight, the minimum number of instances required for a node to be split.\n",
    "# min_child_weight reduces overfitting by increasing its value.\n",
    "grid_search(params={\"min_child_weight\": [1, 2, 3, 4, 5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'subsample': 0.5}\n",
      "Best score: 0.796\n"
     ]
    }
   ],
   "source": [
    "# Tune subsample, the fraction of samples used for fitting the individual base learners.\n",
    "grid_search(params={\"subsample\": [0.5, 0.7, 0.8, 0.9, 1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bytree': 0.9}\n",
      "Best score: 0.796\n"
     ]
    }
   ],
   "source": [
    "# Tune colsample_bytree, the fraction of features used for fitting the individual base learners.\n",
    "# colsample_bytree limits the influence of columns and reduces variance.\n",
    "grid_search(params={\"colsample_bytree\": [0.5, 0.7, 0.8, 0.9, 1]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying early stopping\n",
    "\n",
    "`early_stopping_rounds` is not a hyperparameter, but a strategy for optimizing the `n_estimators` hyperparameter. Early stopping allows us to set a large value for `n_estimators` without worrying about overfitting. The algorithm will stop iterating when the validation score stops improving, even if we aren't at the hard stop for `n_estimators`. This is a very useful feature for avoiding overfitting!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.27632\n",
      "[1]\tvalidation_0-error:0.15789\n",
      "[2]\tvalidation_0-error:0.07895\n",
      "[3]\tvalidation_0-error:0.09211\n",
      "[4]\tvalidation_0-error:0.10526\n",
      "[5]\tvalidation_0-error:0.10526\n",
      "[6]\tvalidation_0-error:0.10526\n",
      "[7]\tvalidation_0-error:0.13158\n",
      "[8]\tvalidation_0-error:0.13158\n",
      "[9]\tvalidation_0-error:0.13158\n",
      "[10]\tvalidation_0-error:0.14474\n",
      "[11]\tvalidation_0-error:0.14474\n",
      "[12]\tvalidation_0-error:0.15789\n",
      "[13]\tvalidation_0-error:0.15789\n",
      "[14]\tvalidation_0-error:0.15789\n",
      "[15]\tvalidation_0-error:0.15789\n",
      "[16]\tvalidation_0-error:0.15789\n",
      "[17]\tvalidation_0-error:0.15789\n",
      "[18]\tvalidation_0-error:0.15789\n",
      "[19]\tvalidation_0-error:0.17105\n",
      "[20]\tvalidation_0-error:0.17105\n",
      "[21]\tvalidation_0-error:0.17105\n",
      "[22]\tvalidation_0-error:0.17105\n",
      "[23]\tvalidation_0-error:0.15789\n",
      "[24]\tvalidation_0-error:0.17105\n",
      "[25]\tvalidation_0-error:0.18421\n",
      "[26]\tvalidation_0-error:0.18421\n",
      "[27]\tvalidation_0-error:0.17105\n",
      "[28]\tvalidation_0-error:0.17105\n",
      "[29]\tvalidation_0-error:0.17105\n",
      "[30]\tvalidation_0-error:0.17105\n",
      "[31]\tvalidation_0-error:0.18421\n",
      "[32]\tvalidation_0-error:0.18421\n",
      "[33]\tvalidation_0-error:0.18421\n",
      "[34]\tvalidation_0-error:0.18421\n",
      "[35]\tvalidation_0-error:0.18421\n",
      "[36]\tvalidation_0-error:0.18421\n",
      "[37]\tvalidation_0-error:0.18421\n",
      "[38]\tvalidation_0-error:0.18421\n",
      "[39]\tvalidation_0-error:0.17105\n",
      "[40]\tvalidation_0-error:0.18421\n",
      "[41]\tvalidation_0-error:0.18421\n",
      "[42]\tvalidation_0-error:0.18421\n",
      "[43]\tvalidation_0-error:0.17105\n",
      "[44]\tvalidation_0-error:0.18421\n",
      "[45]\tvalidation_0-error:0.18421\n",
      "[46]\tvalidation_0-error:0.18421\n",
      "[47]\tvalidation_0-error:0.18421\n",
      "[48]\tvalidation_0-error:0.18421\n",
      "[49]\tvalidation_0-error:0.18421\n",
      "[50]\tvalidation_0-error:0.18421\n",
      "[51]\tvalidation_0-error:0.18421\n",
      "[52]\tvalidation_0-error:0.18421\n",
      "[53]\tvalidation_0-error:0.18421\n",
      "[54]\tvalidation_0-error:0.18421\n",
      "[55]\tvalidation_0-error:0.17105\n",
      "[56]\tvalidation_0-error:0.18421\n",
      "[57]\tvalidation_0-error:0.17105\n",
      "[58]\tvalidation_0-error:0.18421\n",
      "[59]\tvalidation_0-error:0.17105\n",
      "[60]\tvalidation_0-error:0.17105\n",
      "[61]\tvalidation_0-error:0.15789\n",
      "[62]\tvalidation_0-error:0.15789\n",
      "[63]\tvalidation_0-error:0.15789\n",
      "[64]\tvalidation_0-error:0.15789\n",
      "[65]\tvalidation_0-error:0.14474\n",
      "[66]\tvalidation_0-error:0.14474\n",
      "[67]\tvalidation_0-error:0.14474\n",
      "[68]\tvalidation_0-error:0.15789\n",
      "[69]\tvalidation_0-error:0.14474\n",
      "[70]\tvalidation_0-error:0.14474\n",
      "[71]\tvalidation_0-error:0.14474\n",
      "[72]\tvalidation_0-error:0.15789\n",
      "[73]\tvalidation_0-error:0.15789\n",
      "[74]\tvalidation_0-error:0.15789\n",
      "[75]\tvalidation_0-error:0.15789\n",
      "[76]\tvalidation_0-error:0.14474\n",
      "[77]\tvalidation_0-error:0.14474\n",
      "[78]\tvalidation_0-error:0.14474\n",
      "[79]\tvalidation_0-error:0.15789\n",
      "[80]\tvalidation_0-error:0.14474\n",
      "[81]\tvalidation_0-error:0.14474\n",
      "[82]\tvalidation_0-error:0.15789\n",
      "[83]\tvalidation_0-error:0.15789\n",
      "[84]\tvalidation_0-error:0.15789\n",
      "[85]\tvalidation_0-error:0.14474\n",
      "[86]\tvalidation_0-error:0.14474\n",
      "[87]\tvalidation_0-error:0.14474\n",
      "[88]\tvalidation_0-error:0.15789\n",
      "[89]\tvalidation_0-error:0.14474\n",
      "[90]\tvalidation_0-error:0.14474\n",
      "[91]\tvalidation_0-error:0.14474\n",
      "[92]\tvalidation_0-error:0.14474\n",
      "[93]\tvalidation_0-error:0.14474\n",
      "[94]\tvalidation_0-error:0.14474\n",
      "[95]\tvalidation_0-error:0.14474\n",
      "[96]\tvalidation_0-error:0.14474\n",
      "[97]\tvalidation_0-error:0.15789\n",
      "[98]\tvalidation_0-error:0.15789\n",
      "[99]\tvalidation_0-error:0.15789\n",
      "Accuracy: 84.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/graftoncook/.pyenv/versions/3.10.9/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Display an evaluation metric for each round of training with the default number of estimators.\n",
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2)\n",
    "\n",
    "# Initialize the model\n",
    "model = XGBClassifier(booster=\"gbtree\", objective=\"binary:logistic\", random_state=2)\n",
    "\n",
    "# Declare eval_set\n",
    "eval_set = [(X_test, y_test)]\n",
    "\n",
    "# Declare eval_metric\n",
    "eval_metric = \"error\"\n",
    "\n",
    "# Fit the model with eval_metric and eval_set\n",
    "model.fit(X_train, y_train, eval_metric=eval_metric, eval_set=eval_set)\n",
    "\n",
    "# Check the final score\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", np.round(accuracy * 100.0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.27632\n",
      "[1]\tvalidation_0-error:0.15789\n",
      "[2]\tvalidation_0-error:0.07895\n",
      "[3]\tvalidation_0-error:0.09211\n",
      "[4]\tvalidation_0-error:0.10526\n",
      "[5]\tvalidation_0-error:0.10526\n",
      "[6]\tvalidation_0-error:0.10526\n",
      "[7]\tvalidation_0-error:0.13158\n",
      "[8]\tvalidation_0-error:0.13158\n",
      "[9]\tvalidation_0-error:0.13158\n",
      "[10]\tvalidation_0-error:0.14474\n",
      "[11]\tvalidation_0-error:0.14474\n",
      "Accuracy: 92.105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/graftoncook/.pyenv/versions/3.10.9/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/graftoncook/.pyenv/versions/3.10.9/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# early_stopping_rounds is an optional parameter to include with eval_set and eval_metric.\n",
    "# Repeat the previous code with early_stopping_rounds=10 added in\n",
    "model = XGBClassifier(booster=\"gbtree\", objective=\"binary:logistic\", random_state=2)\n",
    "eval_set = [(X_test, y_test)]\n",
    "eval_metric = \"error\"\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_metric=eval_metric,\n",
    "    eval_set=eval_set,\n",
    "    early_stopping_rounds=10,\n",
    "    verbose=True,\n",
    ")\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", np.round(accuracy * 100.0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.27632\n",
      "[1]\tvalidation_0-error:0.15789\n",
      "[2]\tvalidation_0-error:0.07895\n",
      "[3]\tvalidation_0-error:0.09211\n",
      "[4]\tvalidation_0-error:0.10526\n",
      "[5]\tvalidation_0-error:0.10526\n",
      "[6]\tvalidation_0-error:0.10526\n",
      "[7]\tvalidation_0-error:0.13158\n",
      "[8]\tvalidation_0-error:0.13158\n",
      "[9]\tvalidation_0-error:0.13158\n",
      "[10]\tvalidation_0-error:0.14474\n",
      "[11]\tvalidation_0-error:0.14474\n",
      "[12]\tvalidation_0-error:0.15789\n",
      "[13]\tvalidation_0-error:0.15789\n",
      "[14]\tvalidation_0-error:0.15789\n",
      "[15]\tvalidation_0-error:0.15789\n",
      "[16]\tvalidation_0-error:0.15789\n",
      "[17]\tvalidation_0-error:0.15789\n",
      "[18]\tvalidation_0-error:0.15789\n",
      "[19]\tvalidation_0-error:0.17105\n",
      "[20]\tvalidation_0-error:0.17105\n",
      "[21]\tvalidation_0-error:0.17105\n",
      "[22]\tvalidation_0-error:0.17105\n",
      "[23]\tvalidation_0-error:0.15789\n",
      "[24]\tvalidation_0-error:0.17105\n",
      "[25]\tvalidation_0-error:0.18421\n",
      "[26]\tvalidation_0-error:0.18421\n",
      "[27]\tvalidation_0-error:0.17105\n",
      "[28]\tvalidation_0-error:0.17105\n",
      "[29]\tvalidation_0-error:0.17105\n",
      "[30]\tvalidation_0-error:0.17105\n",
      "[31]\tvalidation_0-error:0.18421\n",
      "[32]\tvalidation_0-error:0.18421\n",
      "[33]\tvalidation_0-error:0.18421\n",
      "[34]\tvalidation_0-error:0.18421\n",
      "[35]\tvalidation_0-error:0.18421\n",
      "[36]\tvalidation_0-error:0.18421\n",
      "[37]\tvalidation_0-error:0.18421\n",
      "[38]\tvalidation_0-error:0.18421\n",
      "[39]\tvalidation_0-error:0.17105\n",
      "[40]\tvalidation_0-error:0.18421\n",
      "[41]\tvalidation_0-error:0.18421\n",
      "[42]\tvalidation_0-error:0.18421\n",
      "[43]\tvalidation_0-error:0.17105\n",
      "[44]\tvalidation_0-error:0.18421\n",
      "[45]\tvalidation_0-error:0.18421\n",
      "[46]\tvalidation_0-error:0.18421\n",
      "[47]\tvalidation_0-error:0.18421\n",
      "[48]\tvalidation_0-error:0.18421\n",
      "[49]\tvalidation_0-error:0.18421\n",
      "[50]\tvalidation_0-error:0.18421\n",
      "[51]\tvalidation_0-error:0.18421\n",
      "[52]\tvalidation_0-error:0.18421\n",
      "[53]\tvalidation_0-error:0.18421\n",
      "[54]\tvalidation_0-error:0.18421\n",
      "[55]\tvalidation_0-error:0.17105\n",
      "[56]\tvalidation_0-error:0.18421\n",
      "[57]\tvalidation_0-error:0.17105\n",
      "[58]\tvalidation_0-error:0.18421\n",
      "[59]\tvalidation_0-error:0.17105\n",
      "[60]\tvalidation_0-error:0.17105\n",
      "[61]\tvalidation_0-error:0.15789\n",
      "[62]\tvalidation_0-error:0.15789\n",
      "[63]\tvalidation_0-error:0.15789\n",
      "[64]\tvalidation_0-error:0.15789\n",
      "[65]\tvalidation_0-error:0.14474\n",
      "[66]\tvalidation_0-error:0.14474\n",
      "[67]\tvalidation_0-error:0.14474\n",
      "[68]\tvalidation_0-error:0.15789\n",
      "[69]\tvalidation_0-error:0.14474\n",
      "[70]\tvalidation_0-error:0.14474\n",
      "[71]\tvalidation_0-error:0.14474\n",
      "[72]\tvalidation_0-error:0.15789\n",
      "[73]\tvalidation_0-error:0.15789\n",
      "[74]\tvalidation_0-error:0.15789\n",
      "[75]\tvalidation_0-error:0.15789\n",
      "[76]\tvalidation_0-error:0.14474\n",
      "[77]\tvalidation_0-error:0.14474\n",
      "[78]\tvalidation_0-error:0.14474\n",
      "[79]\tvalidation_0-error:0.15789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/graftoncook/.pyenv/versions/3.10.9/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "/Users/graftoncook/.pyenv/versions/3.10.9/lib/python3.10/site-packages/xgboost/sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80]\tvalidation_0-error:0.14474\n",
      "[81]\tvalidation_0-error:0.14474\n",
      "[82]\tvalidation_0-error:0.15789\n",
      "[83]\tvalidation_0-error:0.15789\n",
      "[84]\tvalidation_0-error:0.15789\n",
      "[85]\tvalidation_0-error:0.14474\n",
      "[86]\tvalidation_0-error:0.14474\n",
      "[87]\tvalidation_0-error:0.14474\n",
      "[88]\tvalidation_0-error:0.15789\n",
      "[89]\tvalidation_0-error:0.14474\n",
      "[90]\tvalidation_0-error:0.14474\n",
      "[91]\tvalidation_0-error:0.14474\n",
      "[92]\tvalidation_0-error:0.14474\n",
      "[93]\tvalidation_0-error:0.14474\n",
      "[94]\tvalidation_0-error:0.14474\n",
      "[95]\tvalidation_0-error:0.14474\n",
      "[96]\tvalidation_0-error:0.14474\n",
      "[97]\tvalidation_0-error:0.15789\n",
      "[98]\tvalidation_0-error:0.15789\n",
      "[99]\tvalidation_0-error:0.15789\n",
      "[100]\tvalidation_0-error:0.15789\n",
      "[101]\tvalidation_0-error:0.15789\n",
      "[102]\tvalidation_0-error:0.15789\n",
      "Accuracy: 92.11%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(random_state=2, n_estimators=5000)\n",
    "eval_set = [(X_test, y_test)]\n",
    "eval_metric = \"error\"\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_metric=eval_metric,\n",
    "    eval_set=eval_set,\n",
    "    early_stopping_rounds=100,\n",
    ")\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining hyperparameters\n",
    "\n",
    "There is no single right way to fine-tune hyperparameters. A good systematic approach is to add one hyperparameter at a time and aggregate results along the way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 100}\n",
      "Best score: 0.793\n"
     ]
    }
   ],
   "source": [
    "# Start with n_estimators\n",
    "grid_search(params={\"n_estimators\": [2, 25, 50, 75, 100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 1, 'n_estimators': 100}\n",
      "Best score: 0.812\n"
     ]
    }
   ],
   "source": [
    "# Move on to max_depth\n",
    "grid_search(params={\"max_depth\": [1, 2, 3, 4, 5, 6, 7, 8], \"n_estimators\": [100]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': 2, 'n_estimators': 50}\n",
      "Best score: 0.806\n"
     ]
    }
   ],
   "source": [
    "# A limitation with keeping only the top values is that we may miss out on better combinations.\n",
    "grid_search(\n",
    "    params={\"max_depth\": [2, 3, 4, 5, 6, 7, 8], \"n_estimators\": [50, 75, 100, 125, 150]}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 50}\n",
      "Best score: 0.809\n"
     ]
    }
   ],
   "source": [
    "# Tune learning_rate\n",
    "grid_search(\n",
    "    params={\n",
    "        \"learning_rate\": [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        \"max_depth\": [2],\n",
    "        \"n_estimators\": [50],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.5, 'max_depth': 2, 'min_child_weight': 1, 'n_estimators': 50}\n",
      "Best score: 0.809\n"
     ]
    }
   ],
   "source": [
    "# Tune min_child_weight\n",
    "grid_search(\n",
    "    params={\n",
    "        \"min_child_weight\": [1, 2, 3, 4, 5],\n",
    "        \"learning_rate\": [0.5],\n",
    "        \"max_depth\": [2],\n",
    "        \"n_estimators\": [50],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.5, 'max_depth': 2, 'n_estimators': 50, 'subsample': 1}\n",
      "Best score: 0.809\n"
     ]
    }
   ],
   "source": [
    "# min_child_weight=1 is the default, so no point in tuning that further.\n",
    "# Tune subsample\n",
    "grid_search(\n",
    "    params={\n",
    "        \"subsample\": [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        \"learning_rate\": [0.5],\n",
    "        \"max_depth\": [2],\n",
    "        \"n_estimators\": [50],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'subsample': 0.9, 'n_estimators': 150, 'min_child_weight': 6, 'max_depth': 1, 'learning_rate': 0.1}\n",
      "Best score: 0.822\n"
     ]
    }
   ],
   "source": [
    "# No improvement with the last few hyperparameters.\n",
    "# Recall that two estimators gave the best results, so let's try a RandomizedSearchCV including that value.\n",
    "grid_search(\n",
    "    params={\n",
    "        \"subsample\": [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        \"min_child_weight\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "        \"learning_rate\": [0.001, 0.01, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        \"max_depth\": [1, 2, 3, 4, 5, 6, 7, 8, None],\n",
    "        \"n_estimators\": [2, 25, 50, 75, 100, 150, 175, 200, 250],\n",
    "    },\n",
    "    random=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bytree': 0.6, 'learning_rate': 0.1, 'max_depth': 1, 'min_child_weight': 6, 'n_estimators': 150, 'subsample': 0.9}\n",
      "Best score: 0.829\n"
     ]
    }
   ],
   "source": [
    "# Let's use the best parameters from the RandomizedSearchCV moving forward and add the colsample hyperparameters\n",
    "grid_search(\n",
    "    params={\n",
    "        \"subsample\": [0.9],\n",
    "        \"min_child_weight\": [6],\n",
    "        \"learning_rate\": [0.1],\n",
    "        \"max_depth\": [1],\n",
    "        \"colsample_bytree\": [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        \"n_estimators\": [150],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bylevel': 0.5, 'colsample_bytree': 0.6, 'learning_rate': 0.1, 'max_depth': 1, 'min_child_weight': 6, 'n_estimators': 150, 'subsample': 0.9}\n",
      "Best score: 0.842\n"
     ]
    }
   ],
   "source": [
    "# colsample_bylevel\n",
    "grid_search(\n",
    "    params={\n",
    "        \"subsample\": [0.9],\n",
    "        \"min_child_weight\": [6],\n",
    "        \"learning_rate\": [0.1],\n",
    "        \"max_depth\": [1],\n",
    "        \"colsample_bytree\": [0.6],\n",
    "        \"colsample_bylevel\": [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        \"n_estimators\": [150],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bylevel': 0.5, 'colsample_bynode': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.1, 'max_depth': 1, 'min_child_weight': 6, 'n_estimators': 150, 'subsample': 0.9}\n",
      "Best score: 0.842\n"
     ]
    }
   ],
   "source": [
    "# colsample_bynode\n",
    "grid_search(\n",
    "    params={\n",
    "        \"subsample\": [0.9],\n",
    "        \"min_child_weight\": [6],\n",
    "        \"learning_rate\": [0.1],\n",
    "        \"max_depth\": [1],\n",
    "        \"colsample_bytree\": [0.6],\n",
    "        \"colsample_bylevel\": [0.5],\n",
    "        \"colsample_bynode\": [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        \"n_estimators\": [150],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bylevel': 0.5, 'colsample_bynode': 1, 'colsample_bytree': 0.6, 'learning_rate': 0.1, 'max_depth': 1, 'min_child_weight': 6, 'n_estimators': 150, 'subsample': 0.9}\n",
      "Best score: 0.842\n"
     ]
    }
   ],
   "source": [
    "# Let's try all three colsample hyperparameters together to see whether we can improve the score.\n",
    "grid_search(\n",
    "    params={\n",
    "        \"subsample\": [0.9],\n",
    "        \"min_child_weight\": [6],\n",
    "        \"learning_rate\": [0.1],\n",
    "        \"max_depth\": [1],\n",
    "        \"colsample_bytree\": [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        \"colsample_bylevel\": [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        \"colsample_bynode\": [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "        \"n_estimators\": [150],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bylevel': 0.5, 'colsample_bynode': 1, 'colsample_bytree': 0.6, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 1, 'min_child_weight': 6, 'n_estimators': 150, 'subsample': 0.9}\n",
      "Best score: 0.842\n"
     ]
    }
   ],
   "source": [
    "# 5% improvement in accuracy with the best parameters. Let's tune gamma.\n",
    "grid_search(\n",
    "    params={\n",
    "        \"subsample\": [0.9],\n",
    "        \"min_child_weight\": [6],\n",
    "        \"learning_rate\": [0.1],\n",
    "        \"max_depth\": [1],\n",
    "        \"colsample_bytree\": [0.6],\n",
    "        \"colsample_bylevel\": [0.5],\n",
    "        \"colsample_bynode\": [1],\n",
    "        \"n_estimators\": [150],\n",
    "        \"gamma\": [0, 0.01, 0.05, 0.1, 0.5, 1, 2, 3],\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
